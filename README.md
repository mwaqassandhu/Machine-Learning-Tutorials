# Machine Learning Algorithms Tutorials
## Muhammad Waqas
## PhD University of Southern California
## Machine Learning | Deep Learning | Autonomous Vehicles | Motion Planning Control

## Overview

Welcome to the Machine Learning Algorithms Tutorials repository! This repository contains in-depth tutorials covering a wide range of machine learning algorithms, including supervised, unsupervised, and semi-supervised learning techniques. Whether you're a beginner looking to learn the basics or an experienced practitioner seeking a deeper understanding, these tutorials are designed to cater to all skill levels.

## Table of Contents

1. [Supervised Learning Algorithms](#supervised-learning-algorithms)
    - Linear Regression
    - Logistic Regression
    - Decision Trees
    - Random Forest
    - Support Vector Machines (SVM)
    - K-Nearest Neighbors (KNN)
    - Naive Bayes
    - Neural Networks (Multi-layer Perceptrons)

2. [Unsupervised Learning Algorithms](#unsupervised-learning-algorithms)
    - K-Means Clustering
    - Hierarchical Clustering
    - Principal Component Analysis (PCA)
    - t-distributed Stochastic Neighbor Embedding (t-SNE)
    - Apriori Algorithm
    - DBSCAN (Density-Based Spatial Clustering of Applications with Noise)

3. [Semi-Supervised Learning Algorithms](#semi-supervised-learning-algorithms)
    - Self-training
    - Co-training
    - Multi-view Learning
    - Label Propagation

## Supervised Learning Algorithms

In this section, you will find tutorials on various supervised learning algorithms. These algorithms are trained on labeled datasets, where the input data is paired with the desired output.

### Linear Regression

Linear regression is a fundamental algorithm for modeling the relationship between a dependent variable and one or more independent variables.

### Logistic Regression

Logistic regression is used for classification tasks, where the output is binary or categorical.

### Decision Trees

Decision trees are versatile algorithms that make decisions based on feature values, resulting in a tree-like structure.

### Random Forest

Random Forest is an ensemble learning technique that combines multiple decision trees to improve predictive accuracy.

### Support Vector Machines (SVM)

SVM is a powerful algorithm for both regression and classification tasks, which finds the optimal hyperplane that best separates classes.

### K-Nearest Neighbors (KNN)

KNN is a simple but effective algorithm that classifies data points based on the majority class of their nearest neighbors.

### Naive Bayes

Naive Bayes is a probabilistic algorithm based on Bayes' theorem, commonly used for classification tasks.

### Neural Networks (Multi-layer Perceptrons)

Neural networks, particularly multi-layer perceptrons, are the foundation of deep learning and can model complex relationships in data.

## Unsupervised Learning Algorithms

This section covers tutorials on unsupervised learning algorithms, which do not rely on labeled data for training.

### K-Means Clustering

K-Means is a popular clustering algorithm that partitions data into 'k' clusters based on similarity.

### Hierarchical Clustering

Hierarchical clustering builds a tree of clusters, allowing for a more detailed understanding of the data's structure.

### Principal Component Analysis (PCA)

PCA is a dimensionality reduction technique that transforms high-dimensional data into a lower-dimensional space while retaining key information.

### t-distributed Stochastic Neighbor Embedding (t-SNE)

t-SNE is a visualization technique used for high-dimensional data, emphasizing the local structure.

### Apriori Algorithm

Apriori is employed in association rule mining, particularly in market basket analysis.

### DBSCAN

DBSCAN is a density-based clustering algorithm that can discover clusters of arbitrary shape.

## Semi-Supervised Learning Algorithms

Semi-supervised learning combines elements of both supervised and unsupervised learning, making it suitable for scenarios where only a portion of the data is labeled.

### Self-training

Self-training is a technique where a model iteratively labels unlabelled data based on its own predictions.

### Co-training

Co-training involves training multiple models on different views of the data, then using each model to label the unlabelled data.

### Multi-view Learning

Multi-view learning deals with situations where multiple sets of features or "views" of the data are available.

### Label Propagation

Label propagation spreads labels from labeled data to unlabelled data based on their similarity.

---

We hope you find these tutorials informative and useful for your machine learning endeavors! If you have any questions or feedback, please don't hesitate to open an issue or contribute to the repository. Happy learning!
