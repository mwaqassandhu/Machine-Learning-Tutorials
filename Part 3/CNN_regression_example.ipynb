{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd9535d1",
   "metadata": {},
   "source": [
    "# Tutorial on Convolutional Neural Networks (CNNs)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are a class of deep learning models specifically designed for processing grid-like data, such as images or audio. They have revolutionized computer vision tasks by achieving state-of-the-art results in various domains. In this tutorial, we'll cover the fundamentals of CNNs and provide examples for both regression and classification tasks using appropriate datasets.\n",
    "\n",
    "## Table of Contents\n",
    "1. **Basics of CNNs**\n",
    "    - 1.1 Convolutional Layers\n",
    "    - 1.2 Pooling Layers\n",
    "    - 1.3 Fully Connected Layers\n",
    "2. **Building a CNN Architecture**\n",
    "    - 2.1 Importing Libraries\n",
    "    - 2.2 Loading and Preprocessing Data\n",
    "    - 2.3 Building the Model\n",
    "    - 2.4 Compiling the Model\n",
    "    - 2.5 Training the Model\n",
    "    - 2.6 Evaluating the Model\n",
    "3. **Regression Example**\n",
    "    - 3.1 Dataset: House Prices Prediction\n",
    "4. **Classification Example**\n",
    "    - 4.1 Dataset: CIFAR-10 Image Classification\n",
    "5. **Conclusion and Further Learning**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Basics of CNNs\n",
    "\n",
    "### 1.1 Convolutional Layers\n",
    "\n",
    "The primary building block of CNNs is the **convolutional layer**. It applies a set of filters to the input, creating feature maps. These filters are learned during the training process and help the network recognize specific patterns.\n",
    "\n",
    "### 1.2 Pooling Layers\n",
    "\n",
    "Pooling layers reduce the spatial dimensions of the feature maps, reducing computation and helping to focus on the most important information.\n",
    "\n",
    "### 1.3 Fully Connected Layers\n",
    "\n",
    "After several convolutional and pooling layers, fully connected layers are added to make predictions based on the features extracted earlier.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Building a CNN Architecture\n",
    "\n",
    "### 2.1 Importing Libraries\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "```\n",
    "\n",
    "### 2.2 Loading and Preprocessing Data\n",
    "\n",
    "Load your dataset and preprocess it according to your task (regression or classification). Ensure your data is properly split into training and testing sets.\n",
    "\n",
    "### 2.3 Building the Model\n",
    "\n",
    "```python\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(width, height, channels)),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(output_units, activation='softmax' if classification else None)\n",
    "])\n",
    "```\n",
    "\n",
    "### 2.4 Compiling the Model\n",
    "\n",
    "```python\n",
    "model.compile(optimizer='adam', loss='mean_squared_error' if regression else 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "### 2.5 Training the Model\n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "```\n",
    "\n",
    "### 2.6 Evaluating the Model\n",
    "\n",
    "```python\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Regression Example\n",
    "\n",
    "### 3.1 Dataset: House Prices Prediction\n",
    "\n",
    "For regression tasks, you'll need a dataset with continuous target values. An example dataset is the California Housing Prices dataset available in scikit-learn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2313da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5f9522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "y = data.target\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0cbecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                576       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,801\n",
      "Trainable params: 4,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.8300 - val_loss: 0.4689\n",
      "Epoch 2/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.3965 - val_loss: 0.3867\n",
      "Epoch 3/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.3661 - val_loss: 0.3599\n",
      "Epoch 4/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.3443 - val_loss: 0.3589\n",
      "Epoch 5/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.3262 - val_loss: 0.3670\n",
      "Epoch 6/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.3249 - val_loss: 0.3368\n",
      "Epoch 7/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.3108 - val_loss: 0.3153\n",
      "Epoch 8/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.3012 - val_loss: 0.3254\n",
      "Epoch 9/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.2961 - val_loss: 0.3427\n",
      "Epoch 10/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.2938 - val_loss: 0.3045\n",
      "Epoch 11/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.2869 - val_loss: 0.3177\n",
      "Epoch 12/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.2866 - val_loss: 0.3132\n",
      "Epoch 13/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.2831 - val_loss: 0.3181\n",
      "Epoch 14/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.2826 - val_loss: 0.3313\n",
      "Epoch 15/20\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 0.2788 - val_loss: 0.3096\n",
      "Epoch 16/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.2769 - val_loss: 0.2894\n",
      "Epoch 17/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.2716 - val_loss: 0.3035\n",
      "Epoch 18/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.2732 - val_loss: 0.2930\n",
      "Epoch 19/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.2670 - val_loss: 0.2922\n",
      "Epoch 20/20\n",
      "516/516 [==============================] - 1s 1ms/step - loss: 0.2678 - val_loss: 0.2893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x233c11a6aa0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define model for regression\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile and train the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7928a0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 963us/step - loss: 0.2893\n",
      "Test loss: 0.2893475294113159\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f'Test loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e7409b",
   "metadata": {},
   "source": [
    "In a regression task, evaluating the model goes beyond accuracy. Here are additional evaluation metrics commonly used for regression tasks:\n",
    "\n",
    "1. **Mean Absolute Error (MAE):**\n",
    "   - MAE measures the average absolute difference between the predicted and true values. It gives an idea of the model's average error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0d58d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 1ms/step\n",
      "Mean Absolute Error: 0.3662292787439069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f'Mean Absolute Error: {mae}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0815c3c",
   "metadata": {},
   "source": [
    "2. **Mean Squared Error (MSE):**\n",
    "   - MSE measures the average squared difference between the predicted and true values. It punishes larger errors more severely.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7f8e84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.28934750066185494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce068eb4",
   "metadata": {},
   "source": [
    "These metrics provide a more comprehensive view of how well the regression model is performing. Keep in mind that the choice of evaluation metric should align with the specific goals of your regression problem. For example, minimizing mean squared error may be more important in certain cases, while in others, understanding the average absolute error might be more informative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181f0931",
   "metadata": {},
   "source": [
    "## 4. Conclusion and Further Learning\n",
    "\n",
    "Congratulations! You've now built a Convolutional Neural Network for both regression and classification tasks. Experiment with different architectures, datasets, and hyperparameters to gain a deeper understanding of CNNs. For further learning, explore advanced techniques like transfer learning, fine-tuning, and object detection with CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b42295a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
